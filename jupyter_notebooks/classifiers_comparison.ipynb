{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "      <th>bankruptcy_after_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.37951</td>\n",
       "      <td>0.39641</td>\n",
       "      <td>2.0472</td>\n",
       "      <td>32.3510</td>\n",
       "      <td>0.38825</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.33050</td>\n",
       "      <td>1.1389</td>\n",
       "      <td>0.50494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39718</td>\n",
       "      <td>0.87804</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>8.4160</td>\n",
       "      <td>5.1372</td>\n",
       "      <td>82.658</td>\n",
       "      <td>4.4158</td>\n",
       "      <td>7.4277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.49988</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>1.9447</td>\n",
       "      <td>14.7860</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.99601</td>\n",
       "      <td>1.6996</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42002</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.1486</td>\n",
       "      <td>3.2732</td>\n",
       "      <td>107.350</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>60.9870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248660</td>\n",
       "      <td>0.69592</td>\n",
       "      <td>0.26713</td>\n",
       "      <td>1.5548</td>\n",
       "      <td>-1.1523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.309060</td>\n",
       "      <td>0.43695</td>\n",
       "      <td>1.3090</td>\n",
       "      <td>0.30408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81774</td>\n",
       "      <td>0.76599</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>4.9909</td>\n",
       "      <td>3.9510</td>\n",
       "      <td>134.270</td>\n",
       "      <td>2.7185</td>\n",
       "      <td>5.2078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.30734</td>\n",
       "      <td>0.45879</td>\n",
       "      <td>2.4928</td>\n",
       "      <td>51.9520</td>\n",
       "      <td>0.14988</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.86610</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>0.57353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14207</td>\n",
       "      <td>0.94598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5746</td>\n",
       "      <td>3.6147</td>\n",
       "      <td>86.435</td>\n",
       "      <td>4.2228</td>\n",
       "      <td>5.5497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.61323</td>\n",
       "      <td>0.22960</td>\n",
       "      <td>1.4063</td>\n",
       "      <td>-7.3128</td>\n",
       "      <td>0.18732</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.63070</td>\n",
       "      <td>1.1559</td>\n",
       "      <td>0.38677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.86515</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>6.3985</td>\n",
       "      <td>4.3158</td>\n",
       "      <td>127.210</td>\n",
       "      <td>2.8692</td>\n",
       "      <td>7.8980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7    Attr8  \\\n",
       "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
       "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
       "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
       "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
       "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
       "\n",
       "    Attr9   Attr10  ...   Attr57   Attr58    Attr59  Attr60  Attr61   Attr62  \\\n",
       "0  1.1389  0.50494  ...  0.39718  0.87804  0.001924  8.4160  5.1372   82.658   \n",
       "1  1.6996  0.49788  ...  0.42002  0.85300  0.000000  4.1486  3.2732  107.350   \n",
       "2  1.3090  0.30408  ...  0.81774  0.76599  0.694840  4.9909  3.9510  134.270   \n",
       "3  1.0571  0.57353  ...  0.14207  0.94598  0.000000  4.5746  3.6147   86.435   \n",
       "4  1.1559  0.38677  ...  0.48431  0.86515  0.124440  6.3985  4.3158  127.210   \n",
       "\n",
       "   Attr63   Attr64  class  bankruptcy_after_years  \n",
       "0  4.4158   7.4277      0                       0  \n",
       "1  3.4000  60.9870      0                       0  \n",
       "2  2.7185   5.2078      0                       0  \n",
       "3  4.2228   5.5497      0                       0  \n",
       "4  2.8692   7.8980      0                       0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "col_names = pd.read_csv('../data/dataset.csv', nrows=0).columns\n",
    "dtype_map = {'class' : np.int16, 'bankruptcy_after_years' : np.int16}\n",
    "dtype_map.update({col: np.float64 for col in col_names if col not in dtype_map})\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv', dtype=dtype_map)\n",
    "df = df.drop([df.columns[0], df.columns[1], df.columns[2], 'year'], axis=1)\n",
    "df.drop_duplicates(keep=False, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost model and k-fold cross-validation, binary classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "           'precision' : make_scorer(precision_score, average='micro'),\n",
    "           'recall' : make_scorer(recall_score, average='micro'), \n",
    "           'f1_score' : make_scorer(f1_score, average='micro')}\n",
    "\n",
    "   \n",
    "    \n",
    "def save_model(model, frs, label, out_dir):\n",
    "    model.fit(frs, label)\n",
    "    pickle.dump(model, open(out_dir,'wb'))\n",
    "\n",
    "\n",
    "def validate(out_dir, frs, label):  \n",
    "    model = pickle.load(open(out_dir,'rb'))   \n",
    "    kfold = KFold(n_splits=5)\n",
    "    return cross_validate(estimator=model, X=frs, y=label, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and save  XGBoost classifier with all features (original data with missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frs = df[df.columns.difference(['bankruptcy_after_years', 'class'])] # with NaNs\n",
    "label = df['bankruptcy_after_years']\n",
    "save_model(xgboost.XGBClassifier(), all_frs, label, '../models/xgboost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cross-validation accuracy, precision, recall, and f1-score for XGBoost classifier fitted on all features with kept NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([144.80531359, 139.43467355, 174.6276567 , 159.52204514,\n",
       "        128.61141706]),\n",
       " 'score_time': array([0.21106172, 0.2135067 , 0.25859308, 0.23638296, 0.17466044]),\n",
       " 'test_accuracy': array([0.96819995, 0.95306266, 0.99941328, 0.94191504, 0.89238352]),\n",
       " 'test_precision': array([0.96819995, 0.95306266, 0.99941328, 0.94191504, 0.89238352]),\n",
       " 'test_recall': array([0.96819995, 0.95306266, 0.99941328, 0.94191504, 0.89238352]),\n",
       " 'test_f1_score': array([0.96819995, 0.95306266, 0.99941328, 0.94191504, 0.89238352])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = validate('../models/xgboost.pkl', all_frs, label)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509948928308628"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509948928308628"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['test_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509948928308628"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['test_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509948928308628"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['test_f1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As it is seen from the 5-fold cross validation results, XGBoost classifier performs well on non-reduced and highly skewed imbalanced data - it means that further data reduction and / or imputation are redundant steps. The dataset chosen for analysis already contains synthetic features, so engineering new ones is not necessary in case of such a high performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve, auc, average_precision_score, roc_curve\n",
    "# import matplotlib as plt\n",
    "\n",
    "# def plot_precision_recall(out_dir, y_test):\n",
    "#     model = pickle.load(open(out_dir,'rb'))  \n",
    "#     class_labels = np.sort(y_test.unique())\n",
    "\n",
    "#     row_count = np.ceil(len(class_labels) / 3).astype(int)\n",
    "#     fig, axes = plt.subplots(row_count, 3, figsize=(15, row_count*5))\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     preds = model.predict_proba(all_frs)\n",
    "\n",
    "#     if len(axes) > len(class_labels):\n",
    "#         for i in range(len(class_labels), len(axes)):\n",
    "#             fig.delaxes(axes[i])\n",
    "\n",
    "#     for i, class_label in enumerate(class_labels):\n",
    "#         axes[i].axhline(sum(y_test == class_label)/len(y_test), color='navy', lw=2, linestyle='--', label='baseline')\n",
    "#         actuals = np.where(y_test == class_label, 1, 0)\n",
    "#         predicted_probabilities = preds[:,i]\n",
    "#         precision, recall, thresholds = precision_recall_curve(actuals, predicted_probabilities)\n",
    "#         auc_score = auc(recall, precision)\n",
    "#         ap_score = average_precision_score(actuals, predicted_probabilities)\n",
    "#         axes[i].plot(recall, precision, lw=2, label=f\"\"\"AUC: {auc_score:.2}; AP : {ap_score:.2}\"\"\")\n",
    "\n",
    "#         axes[i].legend()\n",
    "#         axes[i].set_title(f'Precision-recall curve: class {class_label}')\n",
    "#         axes[i].set_xlabel('Recall')\n",
    "#         axes[i].set_ylabel('Precision')\n",
    "\n",
    "#         axes[i].set_xlim(-0.05, 1.05)\n",
    "#         axes[i].set_ylim(-0.05, 1.05)\n",
    "\n",
    "#     return axes\n",
    "\n",
    "    \n",
    "# plot_precision_recall('../models/xgboost.pkl', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
